# GOTechChallenge

This code scrapes 50 results per page for about 40 departments (pages) and it can be used to compare amazon products from different departments. Scaling to scrape hundreds or even thousands or millions of results is challenging. IP blocking or access could come into play for large scale web scraping. A potential method would be using many proxy servers and running the scraper on each server. Multiprocessing is a way to speed up the scraping process by running multiple processes in parallel, if authentication is needed for API calls, multiple user IDs might be necessary. The multiprocessing library in Python could be used for this purpose. For a smaller project such as this one, multiprocessing is not necessary since processing is still quick, but it can be useful for much larger scraping projects. 
